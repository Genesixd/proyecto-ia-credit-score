{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1343b96a-f134-451b-9bf2-af3ba0b5b41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 6700), (20000, 6700))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar desde pickle (lo que ya guardamos antes)\n",
    "X = pd.read_pickle(\"X_processed.pkl\")\n",
    "y = pd.read_pickle(\"y_labels.pkl\")[\"Credit_Score\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f15058-af17-4810-a3a0-37ae4de6bb78",
   "metadata": {},
   "source": [
    "Escalar los datos con StandardScaler\n",
    "\n",
    "PCA exige escalado, así que primero normalizamos X_train y X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f124fb8-0b21-4dfa-9f6b-3f7ed0ba0f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 6700), (20000, 6700))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# OJO: fit SOLO con train\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03307ff-dcea-4d1c-b2ab-6d961ff53095",
   "metadata": {},
   "source": [
    "Definir el modelo elegido (Random Forest)\n",
    "\n",
    "Usamos el mismo tipo de modelo que ya elegiste como mejor (RandomForest).\n",
    "\n",
    "Puedes fijar algo razonable así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385e5c05-c20d-413a-9bde-db2b1b691a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_base = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcace26f-8eb6-43b5-8cd3-e166a10d0bec",
   "metadata": {},
   "source": [
    "RF sin PCA sobre datos escalados (baseline PCA)\n",
    "\n",
    "Opcional pero útil: RF + datos escalados sin PCA, para comparar con los RF+PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1600099c-f49e-4e85-a194-c0fa1f8c8350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7679, 0.7542461514575364, 0.7453115813389393, 0.7495835861952642)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Entrenar RF con X_train_scaled sin PCA\n",
    "rf_base.fit(X_train_scaled, y_train)\n",
    "y_test_pred_rf_scaled = rf_base.predict(X_test_scaled)\n",
    "\n",
    "acc_rf_scaled = accuracy_score(y_test, y_test_pred_rf_scaled)\n",
    "prec_rf_scaled, rec_rf_scaled, f1_rf_scaled, _ = precision_recall_fscore_support(\n",
    "    y_test, y_test_pred_rf_scaled, average=\"macro\"\n",
    ")\n",
    "\n",
    "acc_rf_scaled, prec_rf_scaled, rec_rf_scaled, f1_rf_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05462715-b226-4dfa-8df8-26854ba783f0",
   "metadata": {},
   "source": [
    "PCA con distintos números de componentes\n",
    "\n",
    "Ahora sí, probamos PCA con [12, 10, 8, 5, 3] componentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f35d974-6dfa-47d1-b7fd-f75b411af729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PCA con 12 componentes ===\n",
      "Accuracy test: 0.6905 | F1_macro: 0.6580\n",
      "\n",
      "=== PCA con 10 componentes ===\n",
      "Accuracy test: 0.6812 | F1_macro: 0.6477\n",
      "\n",
      "=== PCA con 8 componentes ===\n",
      "Accuracy test: 0.6828 | F1_macro: 0.6481\n",
      "\n",
      "=== PCA con 5 componentes ===\n",
      "Accuracy test: 0.6490 | F1_macro: 0.6116\n",
      "\n",
      "=== PCA con 3 componentes ===\n",
      "Accuracy test: 0.6153 | F1_macro: 0.5739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "componentes = [12, 10, 8, 5, 3]\n",
    "\n",
    "resultados_pca = []\n",
    "\n",
    "for n in componentes:\n",
    "    print(f\"\\n=== PCA con {n} componentes ===\")\n",
    "    \n",
    "    # 1. Ajustar PCA sobre X_train_scaled\n",
    "    pca = PCA(n_components=n, random_state=42)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca  = pca.transform(X_test_scaled)\n",
    "    \n",
    "    # 2. Nuevo RandomForest (mismo config)\n",
    "    rf_pca = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    rf_pca.fit(X_train_pca, y_train)\n",
    "    y_test_pred_pca = rf_pca.predict(X_test_pca)\n",
    "    \n",
    "    # 3. Métricas\n",
    "    acc = accuracy_score(y_test, y_test_pred_pca)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred_pca, average=\"macro\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Accuracy test: {acc:.4f} | F1_macro: {f1:.4f}\")\n",
    "    \n",
    "    resultados_pca.append({\n",
    "        \"Modelo\": f\"RF_PCA_{n}\",\n",
    "        \"Componentes\": n,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision_macro\": prec,\n",
    "        \"Recall_macro\": rec,\n",
    "        \"F1_macro\": f1\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292aa05-7825-4fec-a039-16ed665ba2f2",
   "metadata": {},
   "source": [
    "Tabla final de resultados PCA + baseline\n",
    "\n",
    "Armamos el DataFrame comparando:\n",
    "\n",
    "RF sin PCA (datos escalados).\n",
    "\n",
    "RF con PCA para cada N componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "badf3206-13fe-45e5-aaa4-b8e39d4d5af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Componentes</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_macro</th>\n",
       "      <th>F1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_sin_PCA</td>\n",
       "      <td>6700</td>\n",
       "      <td>0.76790</td>\n",
       "      <td>0.754246</td>\n",
       "      <td>0.745312</td>\n",
       "      <td>0.749584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF_PCA_12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.69050</td>\n",
       "      <td>0.669210</td>\n",
       "      <td>0.651335</td>\n",
       "      <td>0.658047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF_PCA_10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68120</td>\n",
       "      <td>0.656672</td>\n",
       "      <td>0.642510</td>\n",
       "      <td>0.647669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_PCA_8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.68280</td>\n",
       "      <td>0.657968</td>\n",
       "      <td>0.641642</td>\n",
       "      <td>0.648128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_PCA_5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.64900</td>\n",
       "      <td>0.622389</td>\n",
       "      <td>0.605059</td>\n",
       "      <td>0.611601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF_PCA_3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.61535</td>\n",
       "      <td>0.583193</td>\n",
       "      <td>0.567783</td>\n",
       "      <td>0.573949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Modelo  Componentes  Accuracy  Precision_macro  Recall_macro  F1_macro\n",
       "0  RF_sin_PCA         6700   0.76790         0.754246      0.745312  0.749584\n",
       "1   RF_PCA_12           12   0.69050         0.669210      0.651335  0.658047\n",
       "2   RF_PCA_10           10   0.68120         0.656672      0.642510  0.647669\n",
       "3    RF_PCA_8            8   0.68280         0.657968      0.641642  0.648128\n",
       "4    RF_PCA_5            5   0.64900         0.622389      0.605059  0.611601\n",
       "5    RF_PCA_3            3   0.61535         0.583193      0.567783  0.573949"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Agregar baseline sin PCA\n",
    "resultados_pca.insert(0, {\n",
    "    \"Modelo\": \"RF_sin_PCA\",\n",
    "    \"Componentes\": X_train_scaled.shape[1],\n",
    "    \"Accuracy\": acc_rf_scaled,\n",
    "    \"Precision_macro\": prec_rf_scaled,\n",
    "    \"Recall_macro\": rec_rf_scaled,\n",
    "    \"F1_macro\": f1_rf_scaled\n",
    "})\n",
    "\n",
    "tabla_pca = pd.DataFrame(resultados_pca)\n",
    "tabla_pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041fb07-2698-4f41-ab45-2289366e60f9",
   "metadata": {},
   "source": [
    "### Análisis de PCA (Reducción de dimensionalidad)\n",
    "\n",
    "Debido a que, después del preprocesamiento y la codificación one-hot, la matriz de características contiene miles de variables (aproximadamente 6 700 columnas), se aplicó Análisis de Componentes Principales (PCA) con el objetivo de reducir la dimensionalidad y analizar el impacto sobre el desempeño del modelo seleccionado (Random Forest).\n",
    "\n",
    "Previo a PCA, todas las variables de entrada se escalaron utilizando `StandardScaler`, ajustando el scaler únicamente con el conjunto de entrenamiento y transformando posteriormente el conjunto de prueba. A partir de estos datos escalados se entrenó un Random Forest en dos escenarios:\n",
    "\n",
    "- Sin reducción de dimensionalidad (RF_sin_PCA).\n",
    "- Con PCA utilizando diferentes cantidades de componentes principales: 12, 10, 8, 5 y 3 componentes.\n",
    "\n",
    "Para cada configuración se evaluó el modelo en el conjunto de prueba mediante Accuracy, Precision macro, Recall macro y F1 macro. Los resultados obtenidos se resumen en la siguiente tabla:\n",
    "\n",
    "*(aquí va la tabla `tabla_pca`)*\n",
    "\n",
    "De la tabla se observa que el modelo **Random Forest sin PCA** alcanza el mejor desempeño global, con un Accuracy cercano a 0.77 y una F1 macro aproximada de 0.75. Al aplicar PCA con **12, 10 u 8 componentes**, el rendimiento disminuye de forma moderada: la F1 macro se sitúa alrededor de 0.65 y el Accuracy baja a un rango de 0.68–0.69. \n",
    "\n",
    "Esta pérdida de aproximadamente **0.09–0.10 puntos de F1 macro** se incrementa al reducir todavía más la dimensionalidad: con 5 componentes la F1 macro desciende a ~0.61 y con 3 componentes a ~0.57, lo que indica que, a partir de cierto punto, la compresión elimina información relevante para la clasificación.\n",
    "\n",
    "En síntesis:\n",
    "\n",
    "- Si el objetivo principal es **maximizar la precisión del modelo**, la mejor opción es mantener el **Random Forest sin PCA**, utilizando todas las variables originales procesadas.\n",
    "- Si se busca un **compromiso entre simplicidad del modelo y rendimiento**, trabajar con PCA y alrededor de **8–12 componentes** permite reducir drásticamente la dimensionalidad de los datos manteniendo un nivel de desempeño aceptable (F1 macro ≈ 0.65).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
